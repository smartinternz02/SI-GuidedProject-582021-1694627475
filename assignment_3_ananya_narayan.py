# -*- coding: utf-8 -*-
"""Assignment-3-Ananya_Narayan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jh7ppsXMtpP1T7eQ0o5QYkJ32YGDeE9f

Importing Libraries
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

"""Imprting Dataset"""

dataset = pd.read_csv('Titanic-Dataset.csv')

dataset=dataset.drop(['Name','Ticket','Cabin','PassengerId'], axis=1)

X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

print(dataset.shape)
print(dataset.dtypes)
print(dataset.info())

"""Visualization"""

#based on percentage on gender

perc = ((dataset['Sex'].value_counts())/len(data))*100
print('percentage of gender:\n',perc)

#Survival of passenegrs based on their sex

v1 = sns.FacetGrid(dataset, col='Survived')
v1.map(plt.hist, 'Sex', alpha=0.5)
v1.add_legend()

sns.catplot(data=data , x='Sex', col='Survived', kind='count')

#Based on their age

v2 = sns.FacetGrid(dataset, col='Survived')

v2.map(plt.hist, 'Age', bins=30)

"""Data Preprosseing"""

#Dropping dulpicate rows

dataset = dataset.drop_duplicates()

"""Checking for missing values:"""

print("missing values in columns: \n",dataset.isna().sum())
msno.matrix(dataset)

"""Putting Values:"""

Age_mean = dataset['Age'].mean()
Age_std = dataset['Age'].std()

num_na = dataset['Age'].isna().sum()

rand_vals = Age_mean + Age_std * np.random.randn(num_na)
dataset.loc[dataset['Age'].isna(), 'Age'] = rand_vals

dataset['Embarked']=dataset['Embarked'].fillna(dataset['Embarked'].mode()[0])

msno.matrix(data)

"""Encoding the Independent Variable"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [w])], remainder='passthrough')
X = np.array(ct.fit_transform(X))

"""Encoding the dependant variable"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

"""Splitting the dataset into Training and Test set"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)

"""Feature Scaling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)